<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="../../../../../documentation2html.xsl"?>
<p1:documents xmlns:p1="http://rapid-i.com/schemas/documentation/reference/1.0"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://rapid-i.com/schemas/documentation/reference/1.0                http://rapid-i.com/schemas/documentation/reference/1.0/documentation.xsd">

    <operator key="operator.streaming:streaming_nest" locale="en" version="7.6.000">

    <title>Streaming Nest</title>

    <synopsis>
        This operator allows to design and deploy streaming analytic processes.
    </synopsis>

    <text>
        <paragraph>
            The streaming analytic process is designed in the subprocess of the Streaming Nest operator.
            A streaming connection (Flink Connection or Spark Connection) has to be provided to the <em>connection</em> input port.
            It defines on which cluster and technology the streaming analytic process is deployed, when the process is executed.
        </paragraph>
        <paragraph>
            If an INFORE optimizer connection object is provided to the <em>connection</em> input port, the streaming workflow is not uploaded to and deployed on a streaming cluster, but the StreamGraph of the workflow is serialized and uploaded to the file server of the INFORE Optimizer Service.
            This graph file can then be used to perform the benchmarking in the INFORE Optimizer.
        </paragraph>
    </text>



    <inputPorts>
        <port name = "connection" type = "com.rapidminer.connection.ConnectionInformationContainerIOObject">
            <paragraph>
                The connection to the streaming cluster (flink or spark), the job shall be deployed on.
            </paragraph>
            <paragraph>
                If an INFORE Optimizer connection object is provided, the StreamGraph defining the streaming workflow is serialized and uploaded to the file server of the INFORE Optimizer Service instead.
            </paragraph>
        </port>
        <port name = "input" type = "com.rapidminer.operator.IOObject">
            <paragraph>
                This port is a port extender, which means if a port is connected a new <em>input</em> port is created.
                Any IOObject can be connected to the port and is passed to the corresponding inner  port.
            </paragraph>
        </port>
    </inputPorts>
    

    <outputPorts>
        <port name = "output" type = "com.rapidminer.operator.IOObject">
            <paragraph>
                This is port is a port extender, which means if a port is connected a new <em>output</em> port is created.
                Any IOObject can be connected to the inner port and is passed to the corresponding outer port.
            </paragraph>
        </port>
    </outputPorts>
    

    <parameters>
        <parameter key = "job_name" >
            <paragraph>
                Name of the stream job.
            </paragraph>
        </parameter>
    </parameters>

    <tutorialProcesses>
        <tutorialProcess key = "process.streaming.streaming_nest.simple_streaming_nest" title = "Simple Streaming Nest">
            <description>
                <paragraph>
                    In this tutorial process the usage of the Streaming Nest operator is demonstrated.
                </paragraph>
            </description>
            <process version="9.8.000">
              <context>
                <input/>
                <output/>
                <macros/>
              </context>
              <operator activated="true" class="process" compatibility="9.8.000" expanded="true" name="Process">
                <parameter key="logverbosity" value="init"/>
                <parameter key="random_seed" value="2001"/>
                <parameter key="send_mail" value="never"/>
                <parameter key="notification_email" value=""/>
                <parameter key="process_duration_for_mail" value="30"/>
                <parameter key="encoding" value="SYSTEM"/>
                <process expanded="true">
                  <operator activated="true" class="retrieve" compatibility="9.8.000" expanded="true" height="68" name="Retrieve Flink Cluster" width="90" x="179" y="34">
                    <parameter key="repository_entry" value="//Local Repository/Connections/Flink Cluster"/>
                  </operator>
                  <operator activated="true" class="streaming:streaming_nest" compatibility="0.1.000-SNAPSHOT" expanded="true" height="82" name="Streaming Nest" width="90" x="380" y="34">
                    <parameter key="job_name" value="test job"/>
                    <process expanded="true">
                      <operator activated="true" class="retrieve" compatibility="9.8.000" expanded="true" height="68" name="Retrieve Kafka Cluster (2)" width="90" x="45" y="34">
                        <parameter key="repository_entry" value="//Local Repository/Connections/Kafka Cluster"/>
                      </operator>
                      <operator activated="true" class="multiply" compatibility="9.8.000" expanded="true" height="124" name="Multiply" width="90" x="179" y="34"/>
                      <operator activated="true" class="streaming:kafka_source" compatibility="0.1.000-SNAPSHOT" expanded="true" height="68" name="Kafka Source (2)" width="90" x="313" y="289">
                        <parameter key="topic" value="input2"/>
                        <parameter key="start_from_earliest" value="false"/>
                      </operator>
                      <operator activated="true" class="streaming:aggregate" compatibility="0.1.000-SNAPSHOT" expanded="true" height="68" name="Aggregate Stream" width="90" x="447" y="289">
                        <parameter key="key" value="partitionKey"/>
                        <parameter key="value_key" value="test"/>
                        <parameter key="window_length" value="5"/>
                        <parameter key="function" value="Average"/>
                      </operator>
                      <operator activated="true" class="streaming:kafka_source" compatibility="0.1.000-SNAPSHOT" expanded="true" height="68" name="Kafka Source" width="90" x="313" y="136">
                        <parameter key="topic" value="input1"/>
                        <parameter key="start_from_earliest" value="false"/>
                      </operator>
                      <operator activated="true" class="streaming:join" compatibility="0.1.000-SNAPSHOT" expanded="true" height="82" name="Join Streams" width="90" x="581" y="136">
                        <parameter key="left_key" value="id"/>
                        <parameter key="right_key" value="id"/>
                        <parameter key="window_length" value="60"/>
                      </operator>
                      <operator activated="true" class="streaming:filter" compatibility="0.1.000-SNAPSHOT" expanded="true" height="68" name="Filter Stream" width="90" x="715" y="136">
                        <parameter key="key" value="test"/>
                        <parameter key="value" value="12"/>
                        <parameter key="operator" value="Less than"/>
                      </operator>
                      <operator activated="true" class="streaming:kafka_sink" compatibility="0.1.000-SNAPSHOT" expanded="true" height="82" name="Kafka Sink" width="90" x="849" y="34">
                        <parameter key="topic" value="output"/>
                      </operator>
                      <connect from_op="Retrieve Kafka Cluster (2)" from_port="output" to_op="Multiply" to_port="input"/>
                      <connect from_op="Multiply" from_port="output 1" to_op="Kafka Sink" to_port="connection"/>
                      <connect from_op="Multiply" from_port="output 2" to_op="Kafka Source" to_port="connection"/>
                      <connect from_op="Multiply" from_port="output 3" to_op="Kafka Source (2)" to_port="connection"/>
                      <connect from_op="Kafka Source (2)" from_port="output stream" to_op="Aggregate Stream" to_port="input stream"/>
                      <connect from_op="Aggregate Stream" from_port="output stream" to_op="Join Streams" to_port="input stream 2"/>
                      <connect from_op="Kafka Source" from_port="output stream" to_op="Join Streams" to_port="input stream 1"/>
                      <connect from_op="Join Streams" from_port="output stream" to_op="Filter Stream" to_port="input stream"/>
                      <connect from_op="Filter Stream" from_port="output stream" to_op="Kafka Sink" to_port="input stream"/>
                      <portSpacing port="source_in 1" spacing="0"/>
                      <portSpacing port="sink_out 1" spacing="0"/>
                    </process>
                    <description align="center" color="transparent" colored="false" width="126">Deploy the designed Streaming Analytic process on the provided Flink Cluster.&lt;br/&gt;&lt;br/&gt;The same process can be deployed on the Spark cluster by just changing the provided connection.</description>
                  </operator>
                  <operator activated="false" class="retrieve" compatibility="9.8.000" expanded="true" height="68" name="Retrieve Spark Cluster" width="90" x="179" y="136">
                    <parameter key="repository_entry" value="//Local Repository/Connections/Spark Cluster"/>
                  </operator>
                  <connect from_op="Retrieve Flink Cluster" from_port="output" to_op="Streaming Nest" to_port="connection"/>
                  <portSpacing port="source_input 1" spacing="0"/>
                  <portSpacing port="sink_result 1" spacing="0"/>
                </process>
              </operator>
            </process>
        </tutorialProcess>
    </tutorialProcesses>
    </operator>
</p1:documents>