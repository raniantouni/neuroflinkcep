version: "3.4"

services:

  jobmanager:
    image: flink:1.12.0-scala_2.12
    ports:
      - "${CLUSTER_3_JM_REST_PORT}:8081"
      - "${CLUSTER_3_JM_WEB_PORT}:8082"
      - "${CLUSTER_3_JM_RPC_PORT}:6123"
      - "9250:9250"
    command: jobmanager
    volumes:
      - type: bind
        source: ./apps/flink
        target: /opt/flink/usrlib
    networks:
      - cluster3_net
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        rest.port: 8081
        flink.web.port: 8082
        taskmanager.data.port: 46121
        taskmanager.rpc.port: 46122
        jobmanager.rpc.port: 46123
        parallelism.default: 1
        web.submit.enable: true
        metrics.reporters: r1
        metrics.reporter.r1.factory.class: org.apache.flink.metrics.jmx.JMXReporterFactory
        metrics.reporter.r1.server.port: 9250
        metrics.delimiter: .
        env.java.opts: -Djava.rmi.server.hostname=host.docker.internal -Dcom.sun.management.jmxremote.port=9250 -Djmx.server.port=9250 -Dcom.sun.management.jmxremote.rmi.port=9250 -Djava.net.preferIPv4Stack=true -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false
    env_file:
      - .env

  taskmanager:
    image: flink:1.12.0-scala_2.12
    depends_on:
      - jobmanager
    command: taskmanager
    ports:
      - "${CLUSTER_3_TM_DATA_PORT}:6121"
      - "${CLUSTER_3_TM_RPC_PORT}:6122"
      - "9251:9251"
    networks:
      - cluster3_net
    volumes:
      - type: bind
        source: ./apps/flink
        target: /opt/flink/usrlib
        read_only: true
    environment:
      - |
        FLINK_PROPERTIES=
        taskmanager.data.port: 6121
        taskmanager.rpc.port: 6122
        jobmanager.rpc.port: 46123
        jobmanager.rpc.address: jobmanager-5
        taskmanager.numberOfTaskSlots: 8
        parallelism.default: 8
        web.submit.enable: true
        taskmanager.memory.framework.heap.size: 128m
        taskmanager.memory.framework.off-heap.size: 128m
        taskmanager.memory.jvm-metaspace.size: 256m
        metrics.reporters: r1
        metrics.reporter.r1.factory.class: org.apache.flink.metrics.jmx.JMXReporterFactory
        metrics.reporter.r1.server.port: 9251
        metrics.delimiter: .
        env.java.opts: -Djava.rmi.server.hostname=host.docker.internal -Dcom.sun.management.jmxremote.port=9251 -Djmx.server.port=9251 -Dcom.sun.management.jmxremote.rmi.port=9251 -Djava.net.preferIPv4Stack=true -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false
    env_file:
      - .env

  zookeeper:
    image: zookeeper:3.4.9
    hostname: zookeeper
    ports:
      - "${CLUSTER_3_ZK_CLIENT_PORT}:${CLUSTER_3_ZK_CLIENT_PORT}"
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: ${CLUSTER_3_ZK_CLIENT_PORT}
      ZOO_SERVERS: server.1=zookeeper:2888:3888
    volumes:
      - ./deployment/kafka/zk_data:/data
      - ./deployment/kafka/zk_datalog:/datalog
    networks:
      - cluster3_net
    env_file:
      - .env

  kafka1:
    image: confluentinc/cp-kafka:5.3.1
    hostname: kafka1
    ports:
      - "${CLUSTER_3_KAFKA1_SERVER_PORT}:${CLUSTER_3_KAFKA1_SERVER_PORT}"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19096,LISTENER_DOCKER_EXTERNAL://${CLUSTER_3_IP}:${CLUSTER_3_KAFKA1_SERVER_PORT}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:${CLUSTER_3_ZK_CLIENT_PORT}"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
    volumes:
      - ./deployment/kafka/k_data1:/var/lib/kafka/data
    depends_on:
      - zookeeper
    networks:
      - cluster3_net
    env_file:
      - .env

  livy-server:
    image: cloudiator/livy-server:latest
    ports:
      - "${CLUSTER_3_LIVY_SERVER_PORT}:8998"
    environment:
      SPARK_MASTER_ENDPOINT: spark-master
      SPARK_MASTER_PORT: 7070
      DEPLOY_MODE: cluster
    networks:
      - cluster3_net
    env_file:
      - .env

  spark-master:
    image: bde2020/spark-master:2.4.5-hadoop2.7
    container_name: spark-master
    ports:
      - "${CLUSTER_3_SPARK_MASTER_UI_PORT}:8080"
      - "${CLUSTER_3_SPARK_MASTER_PORT}:7070"
      - "${CLUSTER_3_SPARK_REST_PORT}:6066"
    environment:
      INIT_DAEMON_STEP: setup_spark
      SPARK_MASTER_HOST: host.docker.internal
      SPARK_MASTER_PORT: 7070
      SPARK_CONF_DIR: /spark/conf
    volumes:
      - ./deployment/spark/home/conf/master:/spark/conf
      - spark_master_volume:/tmp/spark_metrics/master1
    networks:
      - cluster3_net
    env_file:
      - .env

  spark-worker:
    image: bde2020/spark-worker:2.4.5-hadoop2.7
    container_name: spark-worker
    depends_on:
      - spark-master
    ports:
      - "${CLUSTER_3_SPARK_WORKER_UI_PORT}:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7070"
    volumes:
      - spark_worker_volume:/tmp/spark_metrics/worker1
    networks:
      - cluster3_net
    env_file:
      - .env

  logstash:
    build:
      context: ./deployment/elk/logstash
      args:
        ELK_VERSION: ${ELK_VERSION}
    volumes:
      - type: bind
        source: ./deployment/elk/logstash/logstash_cluster_confs/cluster3/monitoring
        target: /usr/share/logstash/monitoring
      - type: bind
        source: ./deployment/elk/logstash/logstash_cluster_confs/cluster3/pipelines.yml
        target: /usr/share/logstash/config/pipelines.yml
      - type: bind
        source: ./deployment/elk/logstash/logstash_cluster_confs/cluster3/logstash.yml
        target: /usr/share/logstash/config/logstash.yml
      - type: bind
        source: ./deployment/elk/logstash/logstash_cluster_confs/cluster3/pipelines
        target: /tmp/config/pipelines
      - type: volume
        source: spark_master_volume
        target: /tmp/spark_metrics/master1
      - type: volume
        source: spark_worker_volume
        target: /tmp/spark_metrics/worker1
    ports:
      - "${CLUSTER_3_LOGSTASH_WEB_API_PORT}:9600"
      - "${CLUSTER_3_LOGSTASH_TCP_INPUT_PORT}:5000"
    environment:
      LS_JAVA_OPTS: "-Xmx4g -Xms256m"
      CLUSTER_NAME: "spring"
    networks:
      - cluster3_net
    env_file:
      - .env

networks:
  cluster3_net:
    driver: bridge

volumes:
  spark_master_volume:
  spark_worker_volume:
